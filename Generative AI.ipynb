{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Generative',\n",
       " 'AI',\n",
       " 'uses',\n",
       " 'algorithms',\n",
       " 'to',\n",
       " 'produce',\n",
       " 'new',\n",
       " 'and',\n",
       " 'unique',\n",
       " 'content',\n",
       " ',',\n",
       " 'like',\n",
       " 'text',\n",
       " ',',\n",
       " 'images',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = 'Generative AI uses algorithms to produce new and unique content, like text, images, and more.'\n",
    "\n",
    "# will make tokens of sample_text\n",
    "tokens = word_tokenize(sample_text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will stop words if repeated\n",
    "stop_words= set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Generative',\n",
       " 'AI',\n",
       " 'uses',\n",
       " 'algorithms',\n",
       " 'produce',\n",
       " 'new',\n",
       " 'unique',\n",
       " 'content',\n",
       " ',',\n",
       " 'like',\n",
       " 'text',\n",
       " ',',\n",
       " 'images',\n",
       " ',',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_text = [word for word in tokens if word.lower() not in stop_words]\n",
    "filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative AI uses algorithms produce new unique content , like text , images , .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text = ' '.join(filtered_text)\n",
    "final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import time\n",
    "\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gener ai use algorithm produc new and uniqu content , like text , imag , and more .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Generative AI uses algorithms producing new and unique content, like text, images, and more.'\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# will perform stemming on each word\n",
    "stemm = [ps.stem(word) for word in tokens]\n",
    "final = ' '.join(stemm)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello these are numbers  and these are not \n"
     ]
    }
   ],
   "source": [
    "def regex_magic(line):\n",
    "    line = re.sub(r'[^\\w\\s]','',line)\n",
    "    line = re.sub(r'\\d+','',line)\n",
    "    \n",
    "    return line\n",
    "\n",
    "line = 'hello!, these are numbers 12345 and these are not @#$%^&*'\n",
    "print(regex_magic(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install transformers\n",
    "!pip install --upgrade torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jBV1bHsL3ay7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Input text\n",
    "input_text = 'THIS IS GENERATIVE AI'\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdL8RDHw3mIS",
    "outputId": "f029e711-0e8d-4ad2-abdc-b493187d09a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " THIS IS GENERATIVE AI.\n",
      "\n",
      "The AI is not a \"human\" or \"computer\" but a \"computer\" that is capable of doing things that humans cannot.\n",
      "\n",
      "The AI is not a \"human\" or \"computer\"\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "output = model.generate(input_ids, max_length=50, do_sample=False)\n",
    "\n",
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print('\\n\\n\\n', generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCGrD6lG3l8D",
    "outputId": "122c395b-111a-49e4-c802-ec6627b58330"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " THIS IS GENERATIVE AI.\n",
      "\n",
      "I'm not saying this is a bad thing, but I'm not saying it's a bad thing.\n",
      "\n",
      "I'm not saying this is a bad thing.\n",
      "\n",
      "I'm not saying this is\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print('\\n\\n\\n', generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-K Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ADwvMwIO3loC",
    "outputId": "f492865d-5e4a-4cb0-be4d-f8b00d9082ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " THIS IS GENERATIVE AI!\n",
      "\n",
      "I'm using this language to test whether or not this code works well. If yes, use it before you start writing or reviewing other code, though. If no, use it later. I just tried this:\n",
      "\n",
      "This is a good idea because you shouldn't rely on Python 2.7 on your machine. It should work well on anything that relies on Python 2.0. For example this code is like:\n",
      "\n",
      "Here, the script\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_length=100, do_sample=True, top_k=50)\n",
    "print('\\n\\n\\n', tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-P Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GW6m3pCK4zvz",
    "outputId": "3f1b7f5b-9278-4a5b-c921-e3584fb2e82e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " THIS IS GENERATIVE AI\n",
      "\n",
      "\n",
      "If you have heard of the game \"The Lord of the Rings\", then you probably already know what the game is. It is set in the world of Middle-earth and contains elements of Tolkien's epic fantasy. It was first published in 1995 and has been played by over 200,000 people. Since then, numerous sequels have been developed. A third game, the next in the series \"A World Without End\" was written in 2007.\n",
      "\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_length=100, do_sample=True, top_p=0.92)\n",
    "print('\\n\\n\\n', tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4-GOHAK5BUJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
